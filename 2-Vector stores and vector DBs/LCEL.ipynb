{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbc4dec",
   "metadata": {},
   "source": [
    "## Create RAG chain alternative - Using LCEL (LangChain Expression Language)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "439924f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "\n",
    "custom_prompt = ChatPromptTemplate.from_template(\"\"\"\n",
    "    Use the following context to answer the question.\n",
    "    If you don't know the answer based on the context, say you don't know the answer.\n",
    "    Provide specific details from the context to support the answer.\n",
    "                                                 \n",
    "    context : {context}\n",
    "    question : {question}\n",
    "    answer:\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3db252cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "\n",
      "First document preview: \n",
      "\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn\n",
      "    and improve from experience without being explicitly programmed. There are ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader, TextLoader\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"data\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'}\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"\\nFirst document preview: \\n\")\n",
    "print(documents[0].page_content[:200]+\"...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1128238",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500, # Maximum size of each chunk\n",
    "    chunk_overlap = 50, # Overlap between chunks to maintain context\n",
    "    length_function = len,\n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"] # Hierarchy of separators\n",
    ")\n",
    "\n",
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fb5411",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents = chunks,\n",
    "    embedding = HuggingFaceEmbeddings(),\n",
    "    persist_directory = persist_directory,\n",
    "    collection_name = \"rag_collection\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "852d706f",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert a vector store to retriever\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    seacrch_kwargs = {\"k\":3} ## Retrieve top 3 chunks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae0cbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.documents import Document\n",
    "\n",
    "## format the o/p document for the prompt\n",
    "def format_docs(docs:Document):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cb9b47fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the gemini api key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini = os.getenv(\"GEMINI_API_KEY\")\n",
    "\n",
    "\n",
    "# Initiating gemini\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=gemini\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853d533e",
   "metadata": {},
   "source": [
    "### Build a chain using LCEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99f6a863",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "rag_chain_lcel = (\n",
    "    {\"context\": retriever | format_docs,\n",
    "     \"question\": RunnablePassthrough() }\n",
    "    | custom_prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c0cdb5be",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Deep learning is a subset of machine learning based on artificial neural networks. These networks are inspired by the human brain and consist of layers of interconnected nodes. Deep learning has revolutionized fields like computer vision, natural language processing, and speech recognition.'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain_lcel.invoke(\"What is deep Learning? \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afe945a8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
