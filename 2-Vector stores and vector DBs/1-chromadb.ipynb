{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79044576",
   "metadata": {},
   "source": [
    "### Building a RAG System with LangChain and ChromaDB\n",
    "#### Introduction\n",
    " Retrieval-Augmented Generation (RAG) is a powerful technique that combines the capabilities of large\n",
    " language models with external knowledge retrieval. \n",
    " This notebook will walk you through building a\n",
    " complete RAG system using:\n",
    "- LangChain: A framework for developing applications powered by language models\n",
    "- ChromaDB: An open-source vector database for storing and retrieving embeddings\n",
    "- OpenAI: For embeddings and language model (you can substitute with other providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "048ccc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive character text splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Vector stores\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# Utility imports\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35973d6",
   "metadata": {},
   "source": [
    "### RAG (Retrieval-Augmented Generation) Architecture:\n",
    "1. Document Loading: Load documents from various sources\n",
    "2. Document Splitting: Break documents into smaller chunks\n",
    "3. Embedding Generation: Convert chunks into vector representations\n",
    "4. Vector Storage: Store embeddings in ChromaDB\n",
    "5. Query Processing: Convert user query to embedding\n",
    "6. Similarity Search: Find relevant chunks from vector store\n",
    "7. Context Augmentation: Combine retrieved chunks with query\n",
    "8. Response Generation: LLM generates answer using context\n",
    "### Benefits of RAG:\n",
    "- Reduces hallucinations\n",
    "- Provides up-to-date information\n",
    "- Allows citing sources\n",
    "- Works with domain-specific knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d911acc3",
   "metadata": {},
   "source": [
    "#### 1. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c1b6d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample data\n",
    "\n",
    "sample_docs = [\n",
    "    \"\"\"Machine Learning Fundamentals\n",
    "\n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn\n",
    "    and improve from experience without being explicitly programmed. There are three main\n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement\n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised\n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through\n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "\n",
    "    Deep learning is a subset of machine learning based on artificial neural networks.\n",
    "    These networks are inspired by the human brain and consist of layers of interconnected\n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language\n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly\n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"Natural Language Processing (NLP)\n",
    "\n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language.\n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis,\n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer\n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand\n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0efc7880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through\\n    interaction with an environment using rewards and penalties.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks.\\n    These networks are inspired by the human brain and consist of layers of interconnected\\n    nodes. Deep learning has revolutionized fields like computer vision, natural language\\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly\\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\\n    excel at sequential data processing.\\n    ',\n",
       " 'Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language.\\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis,\\n    machine translation, and question answering. Modern NLP heavily relies on transformer\\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand\\n    context and relationships between words in text.\\n    ']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "613c4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "for i, doc in enumerate(sample_docs):\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\", \"w\") as f:\n",
    "        f.write(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6d4007d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\monda\\\\AppData\\\\Local\\\\Temp\\\\tmphvq5jmd_'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a2e40",
   "metadata": {},
   "source": [
    "#### 2. Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e3ca88ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "\n",
      "First document preview: \n",
      "\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn\n",
      "    and improve from experience without being explicitly programmed. There are ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# Load documents from directory\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"data\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'}\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"\\nFirst document preview: \\n\")\n",
    "print(documents[0].page_content[:200]+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f92ec3",
   "metadata": {},
   "source": [
    "#### 3. Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb2d0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500, # Maximum size of each chunk\n",
    "    chunk_overlap = 50, # Overlap between chunks to maintain context\n",
    "    length_function = len, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"] # Hierarchy of separators\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5f4b0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6994f7",
   "metadata": {},
   "source": [
    "#### 4. Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d3b09d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Hugging face embedding models\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e56cc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Machine learning is amazing\"\n",
    "embedding1 = embeddings.embed_query(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8945d5a6",
   "metadata": {},
   "source": [
    "#### 5. Initialize the ChromaDB Vector store and stores the chunks in Vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2e57744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 35 vectors\n",
      "Persisted to: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "# create a Chromadb vector store\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "# Initialize chromadb with huggingFace embeddings\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=HuggingFaceEmbeddings(),\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {vector_store._collection.count()} vectors\")\n",
    "print(f\"Persisted to: {persist_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7cd4fd",
   "metadata": {},
   "source": [
    "#### 6. Test similarity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2a090dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the types of machine learning and what is nlp?\"\n",
    "\n",
    "similar_docs = vector_store.similarity_search_with_score(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f4f4ec1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.5402185916900635),\n",
       " (Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.5402185916900635),\n",
       " (Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.5402185916900635),\n",
       " (Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.5402185916900635),\n",
       " (Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.5402185916900635)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "66a6839a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='interaction with an environment using rewards and penalties.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks.\\n    These networks are inspired by the human brain and consist of layers of interconnected\\n    nodes. Deep learning has revolutionized fields like computer vision, natural language\\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly\\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\\n    excel at sequential data processing.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='excel at sequential data processing.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language.\\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis,\\n    machine translation, and question answering. Modern NLP heavily relies on transformer\\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand\\n    context and relationships between words in text.')]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01ce61",
   "metadata": {},
   "source": [
    "#### 2. Understanding Similarity Scores\n",
    "The similarity score represents how closely related a document chunk is to your query. The scoring depends on the distance\n",
    "metric used: \n",
    "\n",
    "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
    "\n",
    "- Lower scores = MORE similar (closer in vector space)\n",
    "- Score of 0 = identical vectors\n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "Cosine similarity (if configured):\n",
    "- Higher scores = MORE similar\n",
    "- Range: -1 to 1 (1 being identical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ae8fff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the gemini api key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed3afe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating gemini\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=gemini\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b1208bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monda\\AppData\\Local\\Temp\\ipykernel_2576\\265053047.py:1: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  test = llm.predict(\"What is a LLM ?\")\n"
     ]
    }
   ],
   "source": [
    "test = llm.predict(\"What is a LLM ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "afb49c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An **LLM** stands for **Large Language Model**.\\n\\nIt\\'s a type of artificial intelligence (AI) program designed to understand, generate, and process human language in a highly sophisticated way.\\n\\nLet\\'s break down what each part of \"Large Language Model\" means:\\n\\n1.  **Large:**\\n    *   **Data:** LLMs are trained on absolutely massive datasets of text and code, often comprising trillions of words gathered from the internet (web pages, books, articles, social media), code repositories, and other sources.\\n    *   **Parameters:** They contain billions, sometimes even trillions, of \"parameters.\" These are the values the model adjusts during training to learn patterns and relationships in the data. More parameters generally mean the model can learn more complex and nuanced patterns.\\n    *   **Size:** Due to the vast data and parameters, these models are computationally very large, requiring significant processing power to train and run.\\n\\n2.  **Language:**\\n    *   This refers specifically to **human language** (natural language). The models learn grammar, syntax, semantics (meaning), context, idioms, and even some factual knowledge implicitly from the text they are trained on.\\n    *   They learn how words and phrases relate to each other and how they combine to form coherent and meaningful sentences and paragraphs.\\n\\n3.  **Model:**\\n    *   In AI, a \"model\" is a system that has been trained to perform a specific task. LLMs are typically based on a neural network architecture called the **Transformer architecture**.\\n    *   The core task they learn during training is to predict the next word in a sequence given the preceding words. By doing this billions of times across immense datasets, they develop a profound statistical understanding of language.\\n\\n**How LLMs Work (Simplified):**\\n\\nImagine you\\'re trying to guess the next word in a sentence: \"The cat sat on the _____.\" An LLM, having processed countless sentences, would assign probabilities to various words (e.g., \"mat,\" \"rug,\" \"couch,\" \"floor,\" \"dog\"). It then picks the most probable and contextually appropriate word to continue the sequence. It repeats this process word-by-word (or token-by-token) to generate longer responses.\\n\\n**Key Capabilities of LLMs:**\\n\\nBecause of this sophisticated predictive ability, LLMs can perform a wide range of language-related tasks:\\n\\n*   **Generate text:** Write articles, stories, poems, emails, code, scripts, etc.\\n*   **Answer questions:** Provide information based on their training data.\\n*   **Summarize text:** Condense long documents into shorter summaries.\\n*   **Translate languages:** Convert text from one language to another.\\n*   **Brainstorm ideas:** Help generate creative concepts or solutions.\\n*   **Explain complex topics:** Break down difficult subjects into simpler terms.\\n*   **Chatbot interactions:** Engage in conversational dialogues.\\n\\n**Important Considerations/Limitations:**\\n\\n*   **Hallucinations:** They can sometimes generate factually incorrect but very plausible-sounding information because they are predicting the *most probable* sequence of words, not necessarily the *truth*.\\n*   **Bias:** They can reflect biases present in their training data, which often comes from human-generated text.\\n*   **Lack of True Understanding:** While they are incredibly good at manipulating language, they don\\'t \"understand\" in the human sense of consciousness or genuine comprehension. They operate based on statistical patterns.\\n*   **Knowledge Cutoff:** Many LLMs have a knowledge cutoff date, meaning they aren\\'t aware of events or information that occurred after their last training update (unless they are specifically integrated with real-time search capabilities).\\n\\n**Examples of Well-Known LLMs:**\\n\\n*   **OpenAI\\'s GPT series** (e.g., GPT-3, GPT-4, which power ChatGPT)\\n*   **Google\\'s PaLM and Gemini**\\n*   **Meta\\'s LLaMA**\\n*   **Anthropic\\'s Claude**\\n\\nIn essence, LLMs are powerful AI tools that have revolutionized how we interact with and generate text, opening up new possibilities across many industries and applications.'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82022029",
   "metadata": {},
   "source": [
    "#### Modern RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "06bdd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "fff48d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert a vector store to retriever\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    seacrch_kwargs = {\"k\":3} ## Retrieve top 3 chunks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d530105d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001B49ED782F0>, search_kwargs={})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9243e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a prompt template\n",
    "\n",
    "system_prompts = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question,\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompts),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5348d45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question,\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "50ed2dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question,\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGoogleGenerativeAI(model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001B4CF7F4620>, default_metadata=(), model_kwargs={})\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create stuff document chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d2a94ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final RAG chain\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a036b4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001B49ED782F0>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question,\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatGoogleGenerativeAI(model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001B4CF7F4620>, default_metadata=(), model_kwargs={})\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c4740c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What is NLP ?',\n",
       " 'context': [Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language.\\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis,\\n    machine translation, and question answering. Modern NLP heavily relies on transformer\\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand\\n    context and relationships between words in text.'),\n",
       "  Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language.\\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis,\\n    machine translation, and question answering. Modern NLP heavily relies on transformer\\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand\\n    context and relationships between words in text.'),\n",
       "  Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language.\\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis,\\n    machine translation, and question answering. Modern NLP heavily relies on transformer\\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand\\n    context and relationships between words in text.'),\n",
       "  Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language.\\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis,\\n    machine translation, and question answering. Modern NLP heavily relies on transformer\\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand\\n    context and relationships between words in text.')],\n",
       " 'answer': 'NLP is a field of Artificial Intelligence (AI) that focuses on the interaction between computers and human language. Its key tasks include text classification, named entity recognition, sentiment analysis, machine translation, and question answering. Modern NLP heavily relies on transformer architectures like BERT, GPT, and T5, which use attention mechanisms to understand context.'}"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\":\"What is NLP ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9671ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
