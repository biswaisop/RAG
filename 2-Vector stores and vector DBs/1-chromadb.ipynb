{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "79044576",
   "metadata": {},
   "source": [
    "### Building a RAG System with LangChain and ChromaDB\n",
    "#### Introduction\n",
    " Retrieval-Augmented Generation (RAG) is a powerful technique that combines the capabilities of large\n",
    " language models with external knowledge retrieval. \n",
    " This notebook will walk you through building a\n",
    " complete RAG system using:\n",
    "- LangChain: A framework for developing applications powered by language models\n",
    "- ChromaDB: An open-source vector database for storing and retrieving embeddings\n",
    "- OpenAI: For embeddings and language model (you can substitute with other providers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7f3acf65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f53c4e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "gemini = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "048ccc71",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recursive character text splitter\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_google_genai import ChatGoogleGenerativeAI\n",
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "from langchain.schema import Document\n",
    "\n",
    "# Vector stores\n",
    "from langchain_community.vectorstores import Chroma\n",
    "\n",
    "\n",
    "# Utility imports\n",
    "import numpy as np\n",
    "from typing import List"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d35973d6",
   "metadata": {},
   "source": [
    "### RAG (Retrieval-Augmented Generation) Architecture:\n",
    "1. Document Loading: Load documents from various sources\n",
    "2. Document Splitting: Break documents into smaller chunks\n",
    "3. Embedding Generation: Convert chunks into vector representations\n",
    "4. Vector Storage: Store embeddings in ChromaDB\n",
    "5. Query Processing: Convert user query to embedding\n",
    "6. Similarity Search: Find relevant chunks from vector store\n",
    "7. Context Augmentation: Combine retrieved chunks with query\n",
    "8. Response Generation: LLM generates answer using context\n",
    "### Benefits of RAG:\n",
    "- Reduces hallucinations\n",
    "- Provides up-to-date information\n",
    "- Allows citing sources\n",
    "- Works with domain-specific knowledge"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d911acc3",
   "metadata": {},
   "source": [
    "#### 1. Sample Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c1b6d64d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create sample data\n",
    "\n",
    "sample_docs = [\n",
    "    \"\"\"Machine Learning Fundamentals\n",
    "\n",
    "    Machine learning is a subset of artificial intelligence that enables systems to learn\n",
    "    and improve from experience without being explicitly programmed. There are three main\n",
    "    types of machine learning: supervised learning, unsupervised learning, and reinforcement\n",
    "    learning. Supervised learning uses labeled data to train models, while unsupervised\n",
    "    learning finds patterns in unlabeled data. Reinforcement learning learns through\n",
    "    interaction with an environment using rewards and penalties.\n",
    "    \"\"\",\n",
    "    \n",
    "    \"\"\"\n",
    "    Deep Learning and Neural Networks\n",
    "\n",
    "    Deep learning is a subset of machine learning based on artificial neural networks.\n",
    "    These networks are inspired by the human brain and consist of layers of interconnected\n",
    "    nodes. Deep learning has revolutionized fields like computer vision, natural language\n",
    "    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly\n",
    "    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\n",
    "    excel at sequential data processing.\n",
    "    \"\"\",\n",
    "\n",
    "    \"\"\"Natural Language Processing (NLP)\n",
    "\n",
    "    NLP is a field of AI that focuses on the interaction between computers and human language.\n",
    "    Key tasks in NLP include text classification, named entity recognition, sentiment analysis,\n",
    "    machine translation, and question answering. Modern NLP heavily relies on transformer\n",
    "    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand\n",
    "    context and relationships between words in text.\n",
    "    \"\"\"\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0efc7880",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Machine Learning Fundamentals\\n\\n    Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through\\n    interaction with an environment using rewards and penalties.\\n    ',\n",
       " '\\n    Deep Learning and Neural Networks\\n\\n    Deep learning is a subset of machine learning based on artificial neural networks.\\n    These networks are inspired by the human brain and consist of layers of interconnected\\n    nodes. Deep learning has revolutionized fields like computer vision, natural language\\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly\\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\\n    excel at sequential data processing.\\n    ',\n",
       " 'Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language.\\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis,\\n    machine translation, and question answering. Modern NLP heavily relies on transformer\\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand\\n    context and relationships between words in text.\\n    ']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "613c4572",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tempfile\n",
    "\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "for i, doc in enumerate(sample_docs):\n",
    "    with open(f\"{temp_dir}/doc_{i}.txt\", \"w\") as f:\n",
    "        f.write(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a6d4007d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\monda\\\\AppData\\\\Local\\\\Temp\\\\tmp57ggche3'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928a2e40",
   "metadata": {},
   "source": [
    "#### 2. Document Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e3ca88ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3 documents\n",
      "\n",
      "First document preview: \n",
      "\n",
      "Machine Learning Fundamentals\n",
      "\n",
      "    Machine learning is a subset of artificial intelligence that enables systems to learn\n",
      "    and improve from experience without being explicitly programmed. There are ...\n"
     ]
    }
   ],
   "source": [
    "from langchain_community.document_loaders import DirectoryLoader\n",
    "\n",
    "# Load documents from directory\n",
    "\n",
    "loader = DirectoryLoader(\n",
    "    \"data\",\n",
    "    glob=\"*.txt\",\n",
    "    loader_cls=TextLoader,\n",
    "    loader_kwargs={'encoding':'utf-8'}\n",
    ")\n",
    "\n",
    "documents = loader.load()\n",
    "\n",
    "print(f\"Loaded {len(documents)} documents\")\n",
    "print(f\"\\nFirst document preview: \\n\")\n",
    "print(documents[0].page_content[:200]+\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3f92ec3",
   "metadata": {},
   "source": [
    "#### 3. Document Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb2d0a90",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(\n",
    "    chunk_size = 500, # Maximum size of each chunk\n",
    "    chunk_overlap = 50, # Overlap between chunks to maintain context\n",
    "    length_function = len, \n",
    "    separators=[\"\\n\\n\", \"\\n\", \". \", \" \", \"\"] # Hierarchy of separators\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5f4b0494",
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks = text_splitter.split_documents(documents)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e6994f7",
   "metadata": {},
   "source": [
    "#### 4. Embedding Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d3b09d43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Study\\RAG\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Hugging face embedding models\n",
    "\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e56cc603",
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_text = \"Machine learning is amazing\"\n",
    "embedding1 = embeddings.embed_query(sample_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8945d5a6",
   "metadata": {},
   "source": [
    "#### 5. Initialize the ChromaDB Vector store and stores the chunks in Vector representation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d2e57744",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vector store created with 28 vectors\n",
      "Persisted to: ./chroma_db\n"
     ]
    }
   ],
   "source": [
    "# create a Chromadb vector store\n",
    "persist_directory = \"./chroma_db\"\n",
    "\n",
    "# Initialize chromadb with huggingFace embeddings\n",
    "vector_store = Chroma.from_documents(\n",
    "    documents=chunks,\n",
    "    embedding=HuggingFaceEmbeddings(),\n",
    "    persist_directory=persist_directory,\n",
    "    collection_name=\"rag_collection\"\n",
    ")\n",
    "\n",
    "print(f\"Vector store created with {vector_store._collection.count()} vectors\")\n",
    "print(f\"Persisted to: {persist_directory}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7cd4fd",
   "metadata": {},
   "source": [
    "#### 6. Test similarity test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2a090dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"What are the types of machine learning and what is nlp?\"\n",
    "\n",
    "similar_docs = vector_store.similarity_search_with_score(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f4f4ec1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.5402185916900635),\n",
       " (Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.5402185916900635),\n",
       " (Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.5402185916900635),\n",
       " (Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       "  0.5402185916900635),\n",
       " (Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language.\\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis,\\n    machine translation, and question answering. Modern NLP heavily relies on transformer\\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand\\n    context and relationships between words in text.'),\n",
       "  0.8147017955780029)]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "similar_docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "66a6839a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine Learning Fundamentals'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='Machine learning is a subset of artificial intelligence that enables systems to learn\\n    and improve from experience without being explicitly programmed. There are three main\\n    types of machine learning: supervised learning, unsupervised learning, and reinforcement\\n    learning. Supervised learning uses labeled data to train models, while unsupervised\\n    learning finds patterns in unlabeled data. Reinforcement learning learns through'),\n",
       " Document(metadata={'source': 'data\\\\doc_0.txt'}, page_content='interaction with an environment using rewards and penalties.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep Learning and Neural Networks'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks.\\n    These networks are inspired by the human brain and consist of layers of interconnected\\n    nodes. Deep learning has revolutionized fields like computer vision, natural language\\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly\\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\\n    excel at sequential data processing.'),\n",
       " Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='excel at sequential data processing.'),\n",
       " Document(metadata={'source': 'data\\\\doc_2.txt'}, page_content='Natural Language Processing (NLP)\\n\\n    NLP is a field of AI that focuses on the interaction between computers and human language.\\n    Key tasks in NLP include text classification, named entity recognition, sentiment analysis,\\n    machine translation, and question answering. Modern NLP heavily relies on transformer\\n    architectures like BERT, GPT, and T5. These models use attention mechanisms to understand\\n    context and relationships between words in text.')]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb01ce61",
   "metadata": {},
   "source": [
    "#### 2. Understanding Similarity Scores\n",
    "The similarity score represents how closely related a document chunk is to your query. The scoring depends on the distance\n",
    "metric used: \n",
    "\n",
    "ChromaDB default: Uses L2 distance (Euclidean distance)\n",
    "\n",
    "- Lower scores = MORE similar (closer in vector space)\n",
    "- Score of 0 = identical vectors\n",
    "- Typical range: 0 to 2 (but can be higher)\n",
    "\n",
    "Cosine similarity (if configured):\n",
    "- Higher scores = MORE similar\n",
    "- Range: -1 to 1 (1 being identical)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ae8fff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading the gemini api key\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "\n",
    "gemini = os.getenv(\"GEMINI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ed3afe19",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initiating gemini\n",
    "\n",
    "llm = ChatGoogleGenerativeAI(\n",
    "    model=\"gemini-2.5-flash\",\n",
    "    google_api_key=gemini\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b1208bfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\monda\\AppData\\Local\\Temp\\ipykernel_20968\\265053047.py:1: LangChainDeprecationWarning: The method `BaseChatModel.predict` was deprecated in langchain-core 0.1.7 and will be removed in 1.0. Use :meth:`~invoke` instead.\n",
      "  test = llm.predict(\"What is a LLM ?\")\n"
     ]
    }
   ],
   "source": [
    "test = llm.predict(\"What is a LLM ?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "afb49c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'An **LLM** stands for **Large Language Model**.\\n\\nIt\\'s a type of artificial intelligence (AI) program that has been trained on a massive amount of text data to understand, generate, and process human language.\\n\\nLet\\'s break down what each part of the name signifies:\\n\\n1.  **Large:**\\n    *   **Parameters:** LLMs typically have billions, even trillions, of parameters (the internal variables that the model learns during training). This vast number allows them to capture incredibly complex patterns and relationships in language.\\n    *   **Data:** They are trained on enormous datasets, often comprising a significant portion of the publicly available text on the internet (books, articles, websites, code, etc.).\\n    *   **Compute:** Training and running these models require immense computational power, usually involving thousands of specialized processors (GPUs).\\n\\n2.  **Language:**\\n    *   This refers to human language (natural language). LLMs are designed to work with text â€“ reading it, writing it, summarizing it, translating it, and understanding its nuances.\\n\\n3.  **Model:**\\n    *   It\\'s a mathematical and computational model, specifically a type of **neural network**. Most modern LLMs are built using a \"Transformer\" architecture, which is highly effective at processing sequences of data like text.\\n\\n**How LLMs Work (Simplified):**\\n\\nAt their core, LLMs are trained to **predict the next word in a sequence**. During their extensive training, they are fed vast amounts of text and learn to identify statistical relationships, grammar rules, factual information, and even some forms of reasoning by observing how words and phrases are used together.\\n\\nWhen you give an LLM a \"prompt\" (a question, a command, or some initial text), it uses its learned patterns to generate a highly probable and coherent sequence of words as a response. It doesn\\'t \"understand\" in the human sense, but rather excels at pattern matching and probabilistic generation.\\n\\n**Key Capabilities and Characteristics:**\\n\\n*   **Text Generation:** Can write articles, stories, emails, code, poems, and more.\\n*   **Question Answering:** Can answer factual questions, summarize information, and explain concepts.\\n*   **Summarization:** Can condense long texts into shorter, coherent summaries.\\n*   **Translation:** Can translate text between different human languages.\\n*   **Code Generation:** Can write, debug, and explain programming code.\\n*   **Contextual Understanding:** Can often grasp the intent and context of complex prompts.\\n*   **Few-shot/Zero-shot Learning:** Can perform tasks it wasn\\'t explicitly trained for, given a few examples or just clear instructions.\\n\\n**Examples of LLMs:**\\n\\n*   **GPT series** (OpenAI, e.g., GPT-3, GPT-4)\\n*   **Gemini** (Google)\\n*   **LLaMA** (Meta)\\n*   **Claude** (Anthropic)\\n\\n**Important Considerations:**\\n\\n*   **Hallucinations:** LLMs can sometimes generate factually incorrect but highly plausible-sounding information.\\n*   **Bias:** They can reflect biases present in their training data.\\n*   **Lack of True Understanding:** They don\\'t have consciousness, emotions, or genuine comprehension of the world.\\n*   **Ethical Concerns:** Issues around misinformation, job displacement, and misuse are ongoing discussions.\\n\\nIn essence, LLMs are incredibly powerful and versatile tools that have revolutionized how we interact with and create text, pushing the boundaries of what AI can achieve in the realm of human language.'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82022029",
   "metadata": {},
   "source": [
    "#### Modern RAG chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "06bdd91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chains import create_retrieval_chain\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fff48d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert a vector store to retriever\n",
    "\n",
    "retriever = vector_store.as_retriever(\n",
    "    seacrch_kwargs = {\"k\":3} ## Retrieve top 3 chunks\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "d530105d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001FC238F45C0>, search_kwargs={})"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9243e91d",
   "metadata": {},
   "outputs": [],
   "source": [
    "## create a prompt template\n",
    "\n",
    "system_prompts = \"\"\"You are an assistant for question-answering tasks.\n",
    "Use the following pieces of retrieved context to answer the question,\n",
    "If you don't know the answer, just say that you don't know.\n",
    "Use three sentences maximum and keep the answer concise\n",
    "\n",
    "Context: {context}\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", system_prompts),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5348d45a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question,\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "50ed2dc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableLambda(format_docs)\n",
       "}), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "| ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question,\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "| ChatGoogleGenerativeAI(model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001FC23AF0B00>, default_metadata=(), model_kwargs={})\n",
       "| StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create stuff document chain\n",
    "\n",
    "from langchain.chains.combine_documents import create_stuff_documents_chain\n",
    "\n",
    "document_chain = create_stuff_documents_chain(llm, prompt)\n",
    "document_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d2a94ee0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the final RAG chain\n",
    "\n",
    "rag_chain = create_retrieval_chain(retriever, document_chain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a036b4de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RunnableBinding(bound=RunnableAssign(mapper={\n",
       "  context: RunnableBinding(bound=RunnableLambda(lambda x: x['input'])\n",
       "           | VectorStoreRetriever(tags=['Chroma', 'HuggingFaceEmbeddings'], vectorstore=<langchain_community.vectorstores.chroma.Chroma object at 0x000001FC238F45C0>, search_kwargs={}), kwargs={}, config={'run_name': 'retrieve_documents'}, config_factories=[])\n",
       "})\n",
       "| RunnableAssign(mapper={\n",
       "    answer: RunnableBinding(bound=RunnableBinding(bound=RunnableAssign(mapper={\n",
       "              context: RunnableLambda(format_docs)\n",
       "            }), kwargs={}, config={'run_name': 'format_inputs'}, config_factories=[])\n",
       "            | ChatPromptTemplate(input_variables=['context', 'input'], input_types={}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=['context'], input_types={}, partial_variables={}, template=\"You are an assistant for question-answering tasks.\\nUse the following pieces of retrieved context to answer the question,\\nIf you don't know the answer, just say that you don't know.\\nUse three sentences maximum and keep the answer concise\\n\\nContext: {context}\"), additional_kwargs={}), HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input'], input_types={}, partial_variables={}, template='{input}'), additional_kwargs={})])\n",
       "            | ChatGoogleGenerativeAI(model='models/gemini-2.5-flash', google_api_key=SecretStr('**********'), client=<google.ai.generativelanguage_v1beta.services.generative_service.client.GenerativeServiceClient object at 0x000001FC23AF0B00>, default_metadata=(), model_kwargs={})\n",
       "            | StrOutputParser(), kwargs={}, config={'run_name': 'stuff_documents_chain'}, config_factories=[])\n",
       "  }), kwargs={}, config={'run_name': 'retrieval_chain'}, config_factories=[])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "c4740c1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input': 'What are neural networks ?',\n",
       " 'context': [Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks.\\n    These networks are inspired by the human brain and consist of layers of interconnected\\n    nodes. Deep learning has revolutionized fields like computer vision, natural language\\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly\\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\\n    excel at sequential data processing.'),\n",
       "  Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks.\\n    These networks are inspired by the human brain and consist of layers of interconnected\\n    nodes. Deep learning has revolutionized fields like computer vision, natural language\\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly\\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\\n    excel at sequential data processing.'),\n",
       "  Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks.\\n    These networks are inspired by the human brain and consist of layers of interconnected\\n    nodes. Deep learning has revolutionized fields like computer vision, natural language\\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly\\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\\n    excel at sequential data processing.'),\n",
       "  Document(metadata={'source': 'data\\\\doc_1.txt'}, page_content='Deep learning is a subset of machine learning based on artificial neural networks.\\n    These networks are inspired by the human brain and consist of layers of interconnected\\n    nodes. Deep learning has revolutionized fields like computer vision, natural language\\n    processing, and speech recognition. Convolutional Neural Networks (CNNs) are particularly\\n    effective for image processing, while Recurrent Neural Networks (RNNs) and Transformers\\n    excel at sequential data processing.')],\n",
       " 'answer': 'Artificial neural networks are the foundation of deep learning. They are inspired by the human brain and composed of layers of interconnected nodes.'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke({\"input\":\"What are neural networks ?\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9671ae4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RAG (3.12.4)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
